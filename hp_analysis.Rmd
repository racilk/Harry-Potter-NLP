---
title: "Intelligent Systems - NLP Deliverable"
author: Racil Kacem
date: January 12, 2021
output:
  pdf_document: default
  html_notebook: default
---

The goal of this document is to analyze the book *Harry Potter and the Order of the Phoenix* which was published on June 21, 2003. 

Indeed, it is the Harry Potter book with the highest number of words. We will try to look to the words which are used (total number of words, total number of unique words, characters, word frequency etc.) and find patterns in the text. 

Thanks to this analysis, we will see that is possible to know who are the most important characters of the book and answer some interesting questions such as: 

  - Who is Harry's closest friend ? 
  - Is this book a negative or positive book ? 

## Preparation

### Check working directory

In this project, we don't have to check the working directory. Indeed, the corpus is hosted online and we'll only need to import it using its link. 

### Load libraries

```{r}
library(reshape2)
library(NLP) 
library(stringr)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(syuzhet)
library(ggplot2)
library(rJava)
.jinit(parameters="-Xmx4g")
library(openNLP) 
library(openNLPmodels.en)
```

## Load corpus

The text file is hosted online on my GithHub repository. 

```{r}
file = "https://github.com/racilk/Harry-Potter-NLP/blob/main/hp.txt?raw=true"
text = readLines(file)
corpus = Corpus(VectorSource(text))
```

We can check the length of the corpus: 

```{r}
length(corpus)
```

## Create a default term document matrix

```{r}
tdm = TermDocumentMatrix(corpus)
```

```{r}
tdm
```

```{r}
length(dimnames(tdm)$Terms)
```

There are 24207 words in this book. Let’s sum the content of all terms (i.e., rows) and see the frequency of the terms just shown.

```{r}
freq=rowSums(as.matrix(tdm))
head(freq,10)
```

If we plot those frequencies ordered, we can see how the corpus behaves following Zipf’s law.

```{r}
plot(sort(freq, decreasing = T),col="blue",main="Word frequencies", xlab="Frequency-based rank", ylab = "Frequency")
```

We can now print the ten most frequent terms. Given that we haven't done any transformation on the text file yet, it will mostly be stopwords. 

```{r}
tail(sort(freq),n=10)
```

An other measure of the vocabulary richness of the book will be the number of words which appear once:

```{r}
sum(freq == 1)
```

We can check that 12600 terms out of 24207 only appear once in our corpus.

## Create a TDM after applying transformations to the corpus

We will now apply transformations to the text in order to delete the stopwords, the numbers, the punctuation etc. First, we can print the different transformations and the stopwords. 

```{r}
getTransformations()
```

```{r}
stopwords()
```

Let's apply the different transformations: 

```{r}
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus,removeWords,stopwords())
corpus = tm_map(corpus,removePunctuation)
corpus = tm_map(corpus,removeNumbers)
corpus = tm_map(corpus,stripWhitespace)
```

Let's inspect the beginning of the book to be sure that the transformations have correctly been applied. 

```{r}
inspect(corpus[1:50])
```

Then, we build the TDM of the transformed corpus in order to display the ten most frequent words (it shouldn't be stopwords now). 

```{r}
corpus_dtm = TermDocumentMatrix(corpus)
dtm_m = as.matrix(corpus_dtm)
dtm_v = sort(rowSums(dtm_m),decreasing=TRUE)
dtm_d = data.frame(word = names(dtm_v),freq=dtm_v)
head(dtm_d, 10)
```
Given that there is a lot of dialogues in this book, the most frequent word is the verb "said". 

It is also possible to plot the most frequent words in another way:

```{r}
barplot(dtm_d[1:10,]$freq, las = 2, names.arg = dtm_d[1:10,]$word,
        col ="lightblue", main ="Most frequent words",
        ylab = "Word frequencies")
```

```{r}
ggplot(head(dtm_d,15), aes(reorder(word,freq), freq)) +   
  geom_bar(stat="identity") + coord_flip() + 
  xlab("Trigrams") + ylab("Frequency") +
  ggtitle("Most frequent words")
```

We can also generate a word cloud of the book:

```{r}
set.seed(1234)
wordcloud(words = dtm_d$word, freq = dtm_d$freq, min.freq = 5,
          max.words=100, random.order=FALSE, rot.per=0.40, 
          colors=brewer.pal(8, "Dark2"))
```

We can see that Ron and Hermione are Harry's best friends. Finally, it is also clear that Sirius and Dumbledore are also close to Harry.  

### Words with a frequency >= 5 

```{r}
corpus_bag = findFreqTerms(corpus_dtm, lowfreq = 5)
class(corpus_bag)
#We can print some of the words that are in our bag of words
corpus_bag[1:50]
```

## Sentiment Analysis

In this part, we are going to discover if the overall sentiment of this book is positive or negative. 

First, we'll need a list of positive and negative words. 

```{r}
pos_file = "http://ptrckprry.com/course/ssd/data/positive-words.txt"
poswords = scan(pos_file, what='character', comment.char=';')
poswords[1:50]
```

```{r}
neg_file = "http://ptrckprry.com/course/ssd/data/negative-words.txt"
negwords = scan(neg_file, what='character', comment.char=';')
negwords[1:50]
```

After that, based on these lists, we can find how many positive and negative words there are in our bag. 

```{r}
match_pos = match(corpus_bag, poswords)
match_pos[1:200]
```

```{r}
match_pos_bool = !is.na(match(corpus_bag, poswords))
match_pos_bool[1:200]
```

```{r}
sum(!is.na(match(corpus_bag, poswords)))
```

There are 220 positive words in our bag (positive words which appear at list five times in the book). 

```{r}
sum(!is.na(match(corpus_bag, negwords)))
```

There are 417 negative words in our bag (negative words which appear at list five times in the book). 

We can calculate the overall score of the book Harry Potter and the Order of the Phoenix: 

```{r}
score = sum(!is.na(match(corpus_bag, poswords))) - sum(!is.na(match(corpus_bag, negwords)))
score
```

We can conclude that this book is a negative book which is the case because there many wars in this story. 

## Conclusions

Let's sum up all the facts that we found by analyzing the text of this book: 

  - Ron and Hermione are Harry's best friends
  - Sirius and Dumbledore are also close to Harry 
  - There are many dialogues in the book (said is the most frequent word of the book)
  - There are about twice as many negative words as positive words in the book: this is a negative book, bad things happen in this story



-----------------













